{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e99697-87b6-41db-a266-00fd497dc27e",
   "metadata": {},
   "source": [
    "# Creating spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfec788-5269-4f4e-b976-3400fc6c42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torchaudio import datasets\n",
    "import numpy as np\n",
    "import os, pathlib\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchaudio import transforms as tf_audio\n",
    "from torchvision import transforms as tf_img\n",
    "from torchvision.transforms import functional as fn\n",
    "import torch.nn.functional as fn_t\n",
    "import torch.nn as nn\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4342e69-9de7-429b-b709-6b1e8d7d6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = \"/home/mpuscian/Desktop/repozytoria/MINI_projects/Transformers/data/processed/splited_data/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f46688-af12-4e85-ae57-366504e591f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valPath = \"/home/mpuscian/Desktop/repozytoria/MINI_projects/Transformers/data/processed/splited_data/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0802d76-9487-41e6-9db1-e901bd44f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorflowDataset:\n",
    "    \"\"\"\n",
    "    Import paths of files\n",
    "    \"\"\"\n",
    "    def __init__(self, directory : str, transforms, DEBUG : bool = False):\n",
    "        self.directory = str\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        self.background_noise_label = \"_background_noise_\"\n",
    "        self.transforms = transforms\n",
    "\n",
    "        for i, (root, dirs, files) in enumerate(os.walk(directory)):\n",
    "\n",
    "            if files:\n",
    "                label = pathlib.Path(root).parts[-1]\n",
    "                if label != self.background_noise_label:\n",
    "                    for file in tqdm(files):\n",
    "                        filepath = os.path.normpath(os.path.join(root, file))\n",
    "                    \n",
    "                        self.paths.append(filepath)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        if not DEBUG:\n",
    "            assert len(np.unique(self.labels)) == 30\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_sr, file_data = wavfile.read(self.paths[idx])\n",
    "        \n",
    "        if self.transforms:\n",
    "            return self.transforms(file_data), self.labels[idx]\n",
    "        else:\n",
    "            return file_data, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960957d0-33db-4de9-af0e-5d3c5e921d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseReducer:\n",
    "    def __init__(self, sample_noise = None, sr=16000, **kwargs):\n",
    "        self.sample_noise = sample_noise\n",
    "        self.kwargs = kwargs\n",
    "        self.sr = sr\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if self.sample_noise:\n",
    "            noise_sample = data[:int(self.sr * 0.5)]\n",
    "        return nr.reduce_noise(y=data, y_noise = noise_sample if self.sample_noise else None, sr=self.sr, **self.kwargs)\n",
    "\n",
    "class Resample:\n",
    "    def __init__(self, sample_rate = 16000):\n",
    "        self.sr = sample_rate\n",
    "    def __call__(self, data):\n",
    "        return librosa.resample(data.astype(float), orig_sr=len(data), target_sr = self.sr)\n",
    "\n",
    "class ToFloatTensor:\n",
    "    def __call__(self, data):\n",
    "        return torch.from_numpy(data).float()\n",
    "\n",
    "class HannWindow:\n",
    "    def __call__(self, data):\n",
    "        return signal.windows.hann(self.window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e620953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding:\n",
    "    \"\"\"\n",
    "    Takes as input image n by m.\n",
    "    Outputs tensor (batch_qantity, num_of_patches, patch_x, patch_y)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dim, patch_dim = (10,10)):\n",
    "        self.img_dim = img_dim\n",
    "        self.patch_dim = patch_dim\n",
    "\n",
    "        assert img_dim[0] % patch_dim[0] == 0\n",
    "        assert img_dim[1] % patch_dim[1] == 0\n",
    "        \n",
    "    def __call__(self, img):\n",
    "\n",
    "        \n",
    "        assert img.dim() == 3 or img.dim() == 2\n",
    "\n",
    "        if img.dim() == 3:\n",
    "            patches = einops.rearrange(\n",
    "            img, \n",
    "            '(b) (h ph) (w pw) -> b (h w) ph pw', \n",
    "            ph=self.patch_dim[0], pw=self.patch_dim[1]\n",
    "            )\n",
    "        elif img.dim() == 2:\n",
    "            patches = einops.rearrange(\n",
    "            img, \n",
    "            '(h ph) (w pw) -> (h w) ph pw', \n",
    "            ph=self.patch_dim[0], pw=self.patch_dim[1]\n",
    "            )\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e7e38d-efa1-46bc-a231-56263444108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (129) may be set too low.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1340/1340 [00:00<00:00, 1519428.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1411/1411 [00:00<00:00, 754194.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1399/1399 [00:00<00:00, 2118350.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1396/1396 [00:00<00:00, 2028845.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1842/1842 [00:00<00:00, 2194860.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1852/1852 [00:00<00:00, 2077521.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1844/1844 [00:00<00:00, 1617715.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1839/1839 [00:00<00:00, 1921605.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1861/1861 [00:00<00:00, 1140669.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1373/1373 [00:00<00:00, 1202501.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1427/1427 [00:00<00:00, 1430856.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1839/1839 [00:00<00:00, 2235746.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1424/1424 [00:00<00:00, 1136356.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:00<00:00, 2236723.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1853/1853 [00:00<00:00, 2207967.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1839/1839 [00:00<00:00, 2044889.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1864/1864 [00:00<00:00, 2240166.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1892/1892 [00:00<00:00, 2003439.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1852/1852 [00:00<00:00, 2009793.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:00<00:00, 1966080.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:00<00:00, 1968725.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1863/1863 [00:00<00:00, 1966277.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1885/1885 [00:00<00:00, 2026727.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1841/1841 [00:00<00:00, 1939641.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1374/1374 [00:00<00:00, 1981084.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1873/1873 [00:00<00:00, 1818081.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1843/1843 [00:00<00:00, 2011476.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1414/1414 [00:00<00:00, 1816461.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1860/1860 [00:00<00:00, 2024235.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1866/1866 [00:00<00:00, 1959091.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 197/197 [00:00<00:00, 1649257.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 1602540.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 168/168 [00:00<00:00, 1616153.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170/170 [00:00<00:00, 1553445.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 264/264 [00:00<00:00, 1672652.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243/243 [00:00<00:00, 1695866.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 1729167.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:00<00:00, 1760727.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 260/260 [00:00<00:00, 1842092.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [00:00<00:00, 1566647.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 1683560.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 247/247 [00:00<00:00, 1817531.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:00<00:00, 1703270.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 230/230 [00:00<00:00, 1646228.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 270/270 [00:00<00:00, 1841401.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 1851279.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 257/257 [00:00<00:00, 1738606.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 230/230 [00:00<00:00, 1830531.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 1813753.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 263/263 [00:00<00:00, 1622208.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 1427848.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 262/262 [00:00<00:00, 1798539.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 246/246 [00:00<00:00, 1816547.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 1831315.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 1771639.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 236/236 [00:00<00:00, 1812922.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 260/260 [00:00<00:00, 1465751.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:00<00:00, 1771639.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 261/261 [00:00<00:00, 988008.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 260/260 [00:00<00:00, 1680306.69it/s]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "patch_dim=(16,15)\n",
    "img_dim=(64, 105)\n",
    "\n",
    "transforms = tf_img.Compose([\n",
    "    NoiseReducer(sample_noise=True, sr=16000, stationary=True),\n",
    "    Resample(sample_rate=16000),\n",
    "    ToFloatTensor(),\n",
    "    tf_audio.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=64, n_fft=256, hop_length=153),\n",
    "    PatchEmbedding(img_dim=img_dim, patch_dim=patch_dim)\n",
    "])\n",
    "\n",
    "\n",
    "trainset = TensorflowDataset(trainPath, transforms=transforms, DEBUG=True)\n",
    "trainloader = data.DataLoader(trainset, batch_size=256, pin_memory=True, num_workers=6, shuffle=True)\n",
    "valset = TensorflowDataset(valPath, transforms=transforms, DEBUG=True)\n",
    "valloader = data.DataLoader(valset, batch_size=256, pin_memory=True, num_workers=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c98458-7645-4e63-a543-4a5652796553",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "output_data_dir = \"processed_data/train/data\"\n",
    "output_label_dir = \"processed_data/train/labels\"\n",
    "os.makedirs(output_data_dir, exist_ok=True)\n",
    "os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "PREPROC_BATCH_SIZE = 256\n",
    "\n",
    "print(f\"Starting pre-processing (batch_size={PREPROC_BATCH_SIZE}) and saving individual items...\")\n",
    "item_count = 0\n",
    "for batch_data, batch_labels in trainloader:\n",
    "    # Loop through each item WITHIN the loaded batch\n",
    "    for i in range(batch_data.size(0)):\n",
    "        data_item = batch_data[i]     # Get the i-th item from the batch\n",
    "        label_item = batch_labels[i] # Get the i-th label from the batch\n",
    "\n",
    "        # Define unique filenames for the individual item\n",
    "        data_filename = os.path.join(output_data_dir, f\"item_{item_count:08d}.pt\")\n",
    "        label_filename = os.path.join(output_label_dir, f\"item_{item_count:08d}.pt\")\n",
    "\n",
    "        # Save the individual transformed tensors\n",
    "        torch.save(data_item, data_filename)\n",
    "        torch.save(label_item, label_filename)\n",
    "\n",
    "        item_count += 1 # Increment counter for each individual item saved\n",
    "\n",
    "        if item_count % 1000 == 0:\n",
    "            print(f\"Saved {item_count} items...\")\n",
    "\n",
    "print(f\"Finished saving {item_count} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23420205-df98-4f72-8ac0-1247f9585e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- In your training script ---\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_dir, online_transforms=None):\n",
    "        self.data_files = sorted(glob.glob(os.path.join(data_dir, \"*.pt\")))\n",
    "        self.label_files = sorted(glob.glob(os.path.join(label_dir, \"*.pt\")))\n",
    "        assert len(self.data_files) == len(self.label_files), \"Mismatch!\"\n",
    "        self.online_transforms = online_transforms # For optional augmentations like SpecAugment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(self.data_files[idx])\n",
    "        label = torch.load(self.label_files[idx])\n",
    "\n",
    "        # Remove batch dim if saved with batch_size=1\n",
    "        # data = data.squeeze(0)\n",
    "        # label = label.squeeze(0)\n",
    "\n",
    "        if self.online_transforms:\n",
    "            data = self.online_transforms(data) # Apply ONLY fast, random augmentations\n",
    "\n",
    "        return data, label\n",
    "\n",
    "processed_train_dataset = PreprocessedDataset(\n",
    "    data_dir=\"processed_data/train/data\",\n",
    "    label_dir=\"processed_data/train/labels\",\n",
    "    online_transforms=None # Or add SpecAugment, etc. here\n",
    ")\n",
    "\n",
    "# Your NEW fast trainloader\n",
    "fast_trainloader = data.DataLoader(\n",
    "    processed_train_dataset,\n",
    "    batch_size=256, # Your desired training batch size\n",
    "    shuffle=True,   # Shuffle the pre-processed items!\n",
    "    num_workers=6,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba628465-9bf0-433b-9f04-89f8e1674c56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def display_spectrogram(spec : torch.tensor):\n",
    "    fig, ax = plt.subplots()\n",
    "    spec_db = librosa.power_to_db(spec.numpy())\n",
    "    ax.imshow(spec_db, origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bc1039d-a514-4b84-adc7-c48c114457d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_spectrogram(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "898553e4-33df-4ad6-86dd-8b7982351402",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m A, alabels = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m display_spectrogram(A[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "A, alabels = next(iter(trainloader))\n",
    "display_spectrogram(A[0][0])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "r, c = 0, 0\n",
    "for i, patch in enumerate(patches[1]):\n",
    "    spec_db = librosa.power_to_db(patch.numpy())\n",
    "    axes[1-r][c].imshow(spec_db, origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    \n",
    "    c += 1\n",
    "    if c >= 2:\n",
    "        c = 0\n",
    "        r += 1\n",
    "        \n",
    "    if r >= 2:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a84907",
   "metadata": {},
   "source": [
    "# Transformer architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407fae41",
   "metadata": {},
   "source": [
    "<img src=\"../reports/figures/transformer_encoder2.png\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4663e-26dc-4972-ab7c-7f06ea3bd128",
   "metadata": {},
   "source": [
    "# Patch embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fa73b",
   "metadata": {},
   "source": [
    "**batch patching test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8ecc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a463ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDev(nn.Module):\n",
    "    def __init__(self, tensor_dims, dropout, feedforward_dim, num_heads):\n",
    "\n",
    "        assert len(tensor_dims) == 4\n",
    "\n",
    "        super().__init__()\n",
    "        self.td = tensor_dims\n",
    "        self.batch_len = tensor_dims[0]\n",
    "        self.embedding_dim = 559\n",
    "        self.LinearEmbedding = nn.Linear(self.td[2] * self.td[3], self.embedding_dim)\n",
    "        self.register_buffer('position_embeddings', torch.arange(start = 1, end = self.td[1] + 1)\n",
    "                             .unsqueeze(0).unsqueeze(2).expand(self.batch_len, self.td[1], 1))\n",
    "\n",
    "        # classification embedding - lenght of pixels in patch\n",
    "        self.clt = nn.Parameter(torch.zeros(1, 1, self.embedding_dim + 1))\n",
    "        self.clt.requires_grad = True\n",
    "\n",
    "        print(self.embedding_dim)\n",
    "        self.MHA = nn.MultiheadAttention(self.embedding_dim + 1, num_heads=num_heads, batch_first=True)\n",
    "        self.MHAs = clones(self.MHA, 20)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(self.embedding_dim + 1)\n",
    "        self.norm2 = nn.LayerNorm(self.embedding_dim + 1)\n",
    "\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.drop_feedforward = nn.Dropout(dropout)\n",
    "\n",
    "        self.lin1 = nn.Linear(self.embedding_dim + 1, feedforward_dim)\n",
    "        self.lin2 = nn.Linear(feedforward_dim, self.embedding_dim + 1)\n",
    "\n",
    "        self.head = nn.Linear(self.embedding_dim + 1, 30)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We start with tensor (B - batch, P - patches, W - width, H - height)\n",
    "        tensor_dims = x.shape\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        try:\n",
    "            x = x.reshape(batch_size, self.td[1], self.td[2] * self.td[3])\n",
    "        except Exception as e:\n",
    "            print(f\"Reshaping {x.shape} to {self.td[0]}, {self.td[1]}, {self.td[2] * self.td[3]}\\n{e}\")\n",
    "        x = self.LinearEmbedding(x)\n",
    "        \n",
    "        # concat number of current patch at the end\n",
    "        x = torch.cat([x, self.position_embeddings[:batch_size]], dim=2)\n",
    "\n",
    "        # concat classification embedding\n",
    "        clt_expanded = self.clt.expand(batch_size, -1, -1)\n",
    "        x = torch.concat([clt_expanded, x], dim=1)\n",
    "\n",
    "        # Pass to MultiHeadAttention\n",
    "        for mha in self.MHAs:\n",
    "            x, attn_weights = mha(x, x, x)\n",
    "        \n",
    "        # Then combine outputs as needed\n",
    "        x2 = torch.stack(x2).mean(dim=0)  # or whatever combining method you need\n",
    "        x = x + self.drop1(x2)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x2 = self.lin2(\n",
    "            self.drop_feedforward(\n",
    "                fn_t.relu(\n",
    "                    self.lin1(x)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        x = x + self.drop2(x2)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        x = self.head(x[:, 0, :])\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79cc5d7-cd7f-410d-a26b-646236bc6341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, time: 4.313716888427734, start from beginning: 4.313745737075806, avg: 4.313749074935913\n",
      "batch 1, time: 0.00010418891906738281, start from beginning: 4.314018964767456, avg: 2.1570099592208862\n",
      "batch 2, time: 0.2173304557800293, start from beginning: 4.531375169754028, avg: 1.510459025700887\n",
      "batch 3, time: 0.0003752708435058594, start from beginning: 4.531886577606201, avg: 1.1329721808433533\n",
      "batch 4, time: 6.866455078125e-05, start from beginning: 4.531994104385376, avg: 0.9063989639282226\n",
      "batch 5, time: 6.890296936035156e-05, start from beginning: 4.532087802886963, avg: 0.7553480863571167\n",
      "batch 6, time: 3.4693992137908936, start from beginning: 8.001516103744507, avg: 1.1430740697043282\n",
      "batch 7, time: 0.01456308364868164, start from beginning: 8.016199111938477, avg: 1.0020250976085663\n",
      "batch 8, time: 0.1731266975402832, start from beginning: 8.189383506774902, avg: 0.9099316596984863\n",
      "batch 9, time: 0.4331092834472656, start from beginning: 8.622561931610107, avg: 0.8622563600540161\n",
      "batch 10, time: 0.00012755393981933594, start from beginning: 8.622798681259155, avg: 0.7838908542286266\n",
      "batch 11, time: 6.628036499023438e-05, start from beginning: 8.622889757156372, avg: 0.7185742060343424\n",
      "batch 12, time: 3.006669282913208, start from beginning: 11.629583358764648, avg: 0.8945834636688232\n",
      "batch 13, time: 0.05935931205749512, start from beginning: 11.689042091369629, avg: 0.8349316801343646\n",
      "batch 14, time: 0.20116376876831055, start from beginning: 11.890259027481079, avg: 0.7926840464274089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m start_absolute = time()\n\u001b[32m      4\u001b[39m start = time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, time: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, start from beginning: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstart_absolute\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, avg: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstart_absolute\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "start_absolute = time()\n",
    "start = time()\n",
    "\n",
    "for i, (patches, labels) in enumerate(trainloader):\n",
    "    print(f\"batch {i}, time: {time()-start}, start from beginning: {time()-start_absolute}, avg: {(time()-start_absolute)/(i+1)}\")\n",
    "    start = time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64503ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 4070 Ti\n",
      "CUDA Version: 12.8\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TransformerDev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model = \u001b[43mTransformerDev\u001b[49m([\u001b[32m512\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m25\u001b[39m, \u001b[32m45\u001b[39m], dropout=\u001b[32m0\u001b[39m, feedforward_dim=\u001b[32m1024\u001b[39m, num_heads=\u001b[32m8\u001b[39m)\n\u001b[32m     12\u001b[39m model = model.to(device)\n\u001b[32m     14\u001b[39m classes = [\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbird\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33meight\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfour\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhappy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnine\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mseven\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msix\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mthree\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtwo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwow\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdown\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfive\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhouse\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarvin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mno\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mon\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msheila\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtree\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mup\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'TransformerDev' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Set device properly with index if needed\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = TransformerDev([512, 4, 25, 45], dropout=0, feedforward_dim=1024, num_heads=8)\n",
    "model = model.to(device)\n",
    "\n",
    "classes = [\n",
    "    'bird', 'dog', 'eight', 'four', 'happy', 'left', 'nine', \n",
    "    'off', 'one', 'seven', 'six', 'three', 'two', 'wow', 'zero',\n",
    "    'bed', 'cat', 'down', 'five', 'go', 'house', 'marvin', 'no',\n",
    "    'on', 'right', 'sheila', 'stop', 'tree', 'up', 'yes'\n",
    "]\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    \n",
    "    for i, (patches, labels) in enumerate(trainloader):\n",
    "        patches= patches.to(device)\n",
    "        label_indices = torch.tensor([class_to_idx[label] for label in labels], device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(patches)\n",
    "        #print(f\"outputs: {outputs}\\nlabel_indices: {label_indices}\")\n",
    "        loss = criterion(outputs, label_indices)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_loss = loss.detach().item()\n",
    "        running_loss += current_loss\n",
    "        batch_loss += current_loss\n",
    "        if i % 50 == 49:\n",
    "            print(f\"Batch {i+1} loss: {batch_loss:.4f}\")\n",
    "            batch_loss = 0.0\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37bd081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V):\n",
    "    \"\"\"\n",
    "    Perform attention operation\n",
    "    \"\"\"\n",
    "    d_k = Q.size(-1)\n",
    "    out = torch.matmul(Q, K.transpose()) / torch.math.sqrt(d_k) # transpose arguments?\n",
    "    out = torch.matmul(out.softmax(), V)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e91805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        d_model : int\n",
    "            Neurons in hidden layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = h\n",
    "        self.d_k = d_model // h\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linears = clones(nn.Linear(d_model), 4)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        \"\"\"\n",
    "        Q = Embedding * W^Q\n",
    "        K = Embedding * W^K\n",
    "        V = Embedding * W^V\n",
    "        \"\"\"\n",
    "\n",
    "        batch_len = Q.size(0)\n",
    "\n",
    "        Q, K, V = [\n",
    "            lin(x).view(batch_len, -1, self.h, self.d_k).transpose(-2, -1)\n",
    "            for lin, x in zip(self.linears, (Q, K, V))\n",
    "        ]\n",
    "        return Q, K, V\n",
    "    # Concat heads\n",
    "    # Matmul W^O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653939f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super.__init__()\n",
    "        self.norm1 = LayerNorm(layer.size)\n",
    "        # MultiHead\n",
    "        # residual connection\n",
    "        # layer normalization\n",
    "        # MLP\n",
    "        # residual connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2978ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProjectionOfPatches(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super.__init__()\n",
    "\n",
    "        self.L1 = nn.Linear(dim_in, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.L1(x)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        img_dim=(50, 90)\n",
    "        patch_dim=(10,10)\n",
    "        Lin1Dim = 128\n",
    "\n",
    "        self.PE = PatchEmbedding(img_dim=img_dim, patch_dim=patch_dim)\n",
    "        self.PELin = LinearProjectionOfPatches(img_dim[0] * img_dim[1], Lin1Dim)\n",
    "\n",
    "        self.clt = nn.Parameter(torch.zeros(Lin1Dim))\n",
    "        self.clt.requires_grad = True\n",
    "\n",
    "        # add positional embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.PE(x)\n",
    "        x = self.PELin(x)\n",
    "        x = torch.concat(x, self.clt)\n",
    "        # Encoder()\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5cc7a",
   "metadata": {},
   "source": [
    "# Classification token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb13da7-f801-4bf0-b663-6cc82c795871",
   "metadata": {},
   "source": [
    "# Positional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9d05",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931594ab",
   "metadata": {},
   "source": [
    "# Residual layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03a715-96ac-43ac-94a4-33173fc9a13c",
   "metadata": {},
   "source": [
    "# Another verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682f8af1-914c-41e2-aad5-7d7ed6ac2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Self-attention + residual + norm\n",
    "        attn_out, _ = self.mha(x, x, x)\n",
    "        x = x + self.dropout1(attn_out)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # FFN + residual + norm\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "class TransformerDev2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 batch_size: int,\n",
    "                 num_patches: int,\n",
    "                 patch_flat: int,\n",
    "                 embed_dim: int = 559,\n",
    "                 num_heads: int = 8,\n",
    "                 ff_dim: int = 1024,\n",
    "                 num_layers: int = 20,\n",
    "                 num_classes: int = 30,\n",
    "                 dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        # patch embedding\n",
    "        self.embed = nn.Linear(patch_flat, embed_dim)\n",
    "        # CLS token\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim + 1))\n",
    "        # positional embeddings for CLS + patches\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, num_patches + 1, embed_dim + 1)\n",
    "        )\n",
    "\n",
    "        # initial projection to embed+1 (we’ll append a position index as a feature)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim + 1)\n",
    "\n",
    "        # stack of transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim + 1, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # classification head (raw logits)\n",
    "        self.head = nn.Linear(embed_dim + 1, num_classes)\n",
    "\n",
    "        # init\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, P, W, H)\n",
    "        B, P, W, H = x.shape\n",
    "        x = x.view(B, P, W * H)              # (B, P, patch_flat)\n",
    "        x = self.embed(x)                    # (B, P, embed_dim)\n",
    "\n",
    "        # project to embed_dim+1 (prep for concatenating pos idx feature)\n",
    "        x = self.proj(x)                     # (B, P, embed_dim+1)\n",
    "\n",
    "        # prepend CLS token\n",
    "        cls = self.cls_token.expand(B, -1, -1)  # (B, 1, embed_dim+1)\n",
    "        x = torch.cat((cls, x), dim=1)          # (B, P+1, embed_dim+1)\n",
    "\n",
    "        # add positional embeddings\n",
    "        x = x + self.pos_embed                 # (B, P+1, embed_dim+1)\n",
    "\n",
    "        # pass through all blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        # take CLS output and project\n",
    "        logits = self.head(x[:, 0])            # (B, num_classes)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e274525d-91d3-42f9-90ba-3f591c3a67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = int(img_dim[0] / patch_dim[0] * img_dim[1] / patch_dim[1])\n",
    "patch_pixels = patch_dim[0] * patch_dim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fc50f1-7e8d-474b-bca0-15d034a2cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = TransformerDev2(\n",
    "    batch_size=512,\n",
    "    num_patches=num_patches,\n",
    "    patch_flat=patch_pixels,\n",
    "    embed_dim=55,\n",
    "    num_heads=8,\n",
    "    ff_dim=1024,\n",
    "    num_layers=20,\n",
    "    num_classes=30,\n",
    "    dropout=0.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6afdc41-20c7-4194-81f3-855026e3fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 4070 Ti\n",
      "CUDA Version: 12.8\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Set device properly with index if needed\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "classes = [\n",
    "    'bird', 'dog', 'eight', 'four', 'happy', 'left', 'nine', \n",
    "    'off', 'one', 'seven', 'six', 'three', 'two', 'wow', 'zero',\n",
    "    'bed', 'cat', 'down', 'five', 'go', 'house', 'marvin', 'no',\n",
    "    'on', 'right', 'sheila', 'stop', 'tree', 'up', 'yes'\n",
    "]\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8c6fee-403d-43c4-b4f4-e1ec8f0d6417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 loss: nan, accuracy: 0.0275\n",
      "Batch 100 loss: nan, accuracy: 0.027109375\n",
      "Batch 150 loss: nan, accuracy: 0.028671875\n",
      "Batch 200 loss: nan, accuracy: 0.027191046658259773\n",
      "Epoch [1/5], Loss: nan\n",
      "Batch 50 loss: nan, accuracy: 0.0275\n",
      "Batch 100 loss: nan, accuracy: 0.028671875\n",
      "Batch 150 loss: nan, accuracy: 0.02671875\n",
      "Batch 200 loss: nan, accuracy: 0.027585119798234553\n",
      "Epoch [2/5], Loss: nan\n",
      "Batch 50 loss: nan, accuracy: 0.02625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     16\u001b[39m no_images = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_indices\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch import amp\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model = torch.compile(model)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    correct = 0\n",
    "    no_images = 0\n",
    "    \n",
    "    for i, (patches, labels) in enumerate(trainloader):\n",
    "        patches= patches.to(device, non_blocking=True)\n",
    "        label_indices = torch.tensor([class_to_idx[label] for label in labels], device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast(device_type='cuda'):\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, label_indices)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        current_loss = loss.detach().item()\n",
    "        running_loss += current_loss\n",
    "        batch_loss += current_loss\n",
    "\n",
    "        correct += (outputs.argmax(dim=1) == label_indices).sum().item()\n",
    "        no_images += patches.shape[0]\n",
    "        \n",
    "        if i % 50 == 49:\n",
    "            print(f\"Batch {i+1} loss: {batch_loss:.4f}, accuracy: {correct/no_images}\")\n",
    "            batch_loss = 0.0\n",
    "            correct = 0\n",
    "            no_images = 0\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead9f9e-2e03-420b-86ea-337e12ed2411",
   "metadata": {},
   "source": [
    "# Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1cfa31a-bfc0-467f-a1e0-5314d04f25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimensions: (64, 105)\n",
      "Patch Dimensions: (16, 15)\n",
      "Number of Patches: 28\n",
      "Patch Flattened Size: 240\n",
      "\n",
      "--- Device Setup ---\n",
      "CUDA Available: True\n",
      "Using CUDA Device: NVIDIA GeForce RTX 4070 Ti\n",
      "CUDA Version: 12.8\n",
      "\n",
      "--- Model Instantiation ---\n",
      "Model created with embed_dim=64\n",
      "Model compiled successfully.\n",
      "\n",
      "--- Training Setup ---\n",
      "AMP GradScaler enabled: False\n",
      "\n",
      "--- Starting Training Loop ---\n",
      "Epoch [1/5], Batch [50/200], Avg Batch Loss: 3.4208, Batch Accuracy: 0.0373\n",
      "Epoch [1/5], Batch [100/200], Avg Batch Loss: 3.3891, Batch Accuracy: 0.0393\n",
      "Epoch [1/5], Batch [150/200], Avg Batch Loss: 3.2755, Batch Accuracy: 0.0780\n",
      "Epoch [1/5], Batch [200/200], Avg Batch Loss: 3.1990, Batch Accuracy: 0.0941\n",
      "--- Epoch [1/5] Summary ---\n",
      "Average Loss: 3.3211, Overall Accuracy: 0.0621\n",
      "------------------------------\n",
      "Epoch [2/5], Batch [50/200], Avg Batch Loss: 3.0557, Batch Accuracy: 0.1311\n",
      "Epoch [2/5], Batch [100/200], Avg Batch Loss: 2.9168, Batch Accuracy: 0.1692\n",
      "Epoch [2/5], Batch [150/200], Avg Batch Loss: 2.7792, Batch Accuracy: 0.2070\n",
      "Epoch [2/5], Batch [200/200], Avg Batch Loss: 2.7306, Batch Accuracy: 0.2174\n",
      "--- Epoch [2/5] Summary ---\n",
      "Average Loss: 2.8706, Overall Accuracy: 0.1811\n",
      "------------------------------\n",
      "Epoch [3/5], Batch [50/200], Avg Batch Loss: 2.6750, Batch Accuracy: 0.2330\n",
      "Epoch [3/5], Batch [100/200], Avg Batch Loss: 2.5865, Batch Accuracy: 0.2536\n",
      "Epoch [3/5], Batch [150/200], Avg Batch Loss: 2.5606, Batch Accuracy: 0.2601\n",
      "Epoch [3/5], Batch [200/200], Avg Batch Loss: 2.4921, Batch Accuracy: 0.2787\n",
      "--- Epoch [3/5] Summary ---\n",
      "Average Loss: 2.5785, Overall Accuracy: 0.2563\n",
      "------------------------------\n",
      "Epoch [4/5], Batch [50/200], Avg Batch Loss: 2.4593, Batch Accuracy: 0.2930\n",
      "Epoch [4/5], Batch [100/200], Avg Batch Loss: 2.4319, Batch Accuracy: 0.3014\n",
      "Epoch [4/5], Batch [150/200], Avg Batch Loss: 2.3717, Batch Accuracy: 0.3173\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 227\u001b[39m\n\u001b[32m    223\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m    225\u001b[39m print_every = \u001b[32m50\u001b[39m \u001b[38;5;66;03m# Print stats every 50 batches\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfast_trainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Check if batch format is correct\u001b[39;49;00m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m         \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError: DataLoader yielding unexpected batch format: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. Expected (patches, labels).\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-148:\n",
      "Process Process-145:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-146:\n",
      "Process Process-149:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "Process Process-150:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "Process Process-147:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 372, in _worker_loop\n",
      "    if done_event.is_set():\n",
      "       ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/multiprocessing/synchronize.py\", line 334, in is_set\n",
      "    def is_set(self):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.13/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "                     \"__main__\", mod_spec)\n",
      "  File \"/usr/lib64/python3.13/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/asyncio/base_events.py\", line 677, in run_forever\n",
      "    self._run_once()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib64/python3.13/asyncio/base_events.py\", line 1996, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.13/selectors.py\", line 452, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/home/mpuscian/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "RuntimeError: DataLoader worker (pid 140430) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import amp # For automatic mixed precision\n",
    "\n",
    "# --- Transformer Block Definition (Unchanged) ---\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        # batch_first=True expects input shape (Batch, Sequence, Features)\n",
    "        self.mha = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(inplace=True), # Using inplace ReLU can save memory\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-Normalization variation (Norm -> Attention -> Residual)\n",
    "        # Self-attention + residual + norm\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.mha(x_norm, x_norm, x_norm) # Q=K=V for self-attention\n",
    "        x = x + self.dropout1(attn_out)\n",
    "        # x = self.norm1(x) # Original post-norm location\n",
    "\n",
    "        # Pre-Normalization variation (Norm -> FFN -> Residual)\n",
    "        # FFN + residual + norm\n",
    "        x_norm = self.norm2(x)\n",
    "        ffn_out = self.ffn(x_norm)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "        # x = self.norm2(x) # Original post-norm location\n",
    "        return x\n",
    "\n",
    "# --- Simplified Transformer Model Definition ---\n",
    "class TransformerSimplified(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_patches: int,\n",
    "                 patch_flat: int,          # Number of features per flattened patch\n",
    "                 embed_dim: int = 64,      # Simplified: Divisible by num_heads\n",
    "                 num_heads: int = 8,\n",
    "                 ff_dim: int = 1024,       # Feedforward dimension\n",
    "                 num_layers: int = 20,     # Number of Transformer blocks\n",
    "                 num_classes: int = 30,\n",
    "                 dropout: float = 0.1):   # Added dropout\n",
    "        super().__init__()\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embed_dim ({embed_dim}) must be divisible by num_heads ({num_heads})\")\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        # 1. Patch embedding layer\n",
    "        self.embed = nn.Linear(patch_flat, embed_dim)\n",
    "\n",
    "        # 2. CLS token parameter\n",
    "        # Shape: (1, 1, embed_dim) - batch, seq_len=1, features\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "\n",
    "        # 3. Positional embeddings for CLS token + patches\n",
    "        # Shape: (1, num_patches + 1, embed_dim) - batch, seq_len=P+1, features\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, num_patches + 1, embed_dim)\n",
    "        )\n",
    "        # Removed the proj layer: nn.Linear(embed_dim, embed_dim + 1)\n",
    "\n",
    "        # 4. Stack of transformer blocks\n",
    "        # Each block operates on embed_dim\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # 5. Final LayerNorm (often helpful before the classification head)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # 6. Classification head (takes the CLS token output)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        # Initialization\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        # Initialize linear layers (optional but good practice)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "             nn.init.zeros_(m.bias)\n",
    "             nn.init.ones_(m.weight)\n",
    "        elif isinstance(m, nn.Parameter): # For cls_token, pos_embed if not handled separately\n",
    "             if m.dim() > 1:\n",
    "                 nn.init.trunc_normal_(m, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (B, P, W, H) - Batch, NumPatches, PatchWidth, PatchHeight\n",
    "        B = x.shape[0]\n",
    "        P = self.num_patches # Should match x.shape[1] if input is correct\n",
    "        # Flatten patches: (B, P, W*H)\n",
    "        x = x.view(B, P, -1)\n",
    "\n",
    "        # Embed patches: (B, P, W*H) -> (B, P, embed_dim)\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # Prepend CLS token\n",
    "        # Expand CLS token to match batch size: (1, 1, embed_dim) -> (B, 1, embed_dim)\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        # Concatenate along sequence dimension: (B, 1+P, embed_dim)\n",
    "        x = torch.cat((cls, x), dim=1)\n",
    "\n",
    "        # Add positional embeddings\n",
    "        # pos_embed shape: (1, P+1, embed_dim) - broadcasts across batch dimension\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        # Pass through all transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        # Apply final LayerNorm\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # Take the output corresponding to the CLS token (index 0)\n",
    "        cls_output = x[:, 0] # Shape: (B, embed_dim)\n",
    "\n",
    "        # Pass CLS token output through the classification head\n",
    "        logits = self.head(cls_output) # Shape: (B, num_classes)\n",
    "        return logits\n",
    "\n",
    "batch_size = 512 # From original code\n",
    "num_classes = 30 # From original code\n",
    "\n",
    "# Calculate number of patches and flattened patch size\n",
    "if (img_dim[0] % patch_dim[0] != 0) or (img_dim[1] % patch_dim[1] != 0):\n",
    "    raise ValueError(\"Image dimensions must be divisible by patch dimensions\")\n",
    "\n",
    "num_patches_h = img_dim[0] // patch_dim[0]\n",
    "num_patches_w = img_dim[1] // patch_dim[1]\n",
    "num_patches = num_patches_h * num_patches_w\n",
    "patch_flat = patch_dim[0] * patch_dim[1] * 1 # Assuming 1 channel (e.g., grayscale) - Adjust if using RGB (multiply by 3)\n",
    "\n",
    "print(f\"Image Dimensions: {img_dim}\")\n",
    "print(f\"Patch Dimensions: {patch_dim}\")\n",
    "print(f\"Number of Patches: {num_patches}\")\n",
    "print(f\"Patch Flattened Size: {patch_flat}\")\n",
    "\n",
    "# --- Device Setup ---\n",
    "print(\"\\n--- Device Setup ---\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") # Use specific GPU if available\n",
    "    print(f\"CUDA Available: True\")\n",
    "    print(f\"Using CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.backends.cudnn.benchmark = True # Enable CuDNN benchmark mode\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"CUDA Available: False\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Model Instantiation ---\n",
    "print(\"\\n--- Model Instantiation ---\")\n",
    "model = TransformerSimplified(\n",
    "    num_patches=num_patches,\n",
    "    patch_flat=patch_flat,\n",
    "    embed_dim=256,      # Simplified: Multiple of num_heads (8)\n",
    "    num_heads=8,       # Keep as 8\n",
    "    ff_dim=1024,       # Feedforward dimension\n",
    "    num_layers=20,     # Keep as 20\n",
    "    num_classes=num_classes,\n",
    "    dropout=0.1        # Added dropout\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created with embed_dim={model.embed_dim}\")\n",
    "# Compile the model (optional, requires PyTorch 2.0+)\n",
    "# Can sometimes improve speed but might hide errors initially.\n",
    "# Comment out if issues persist after other changes.\n",
    "try:\n",
    "    model = torch.compile(model)\n",
    "    print(\"Model compiled successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Model compilation failed: {e}. Proceeding without compilation.\")\n",
    "\n",
    "\n",
    "# Optimizer with reduced learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3) # REDUCED LR\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Automatic Mixed Precision Scaler\n",
    "# Use enabled=True/False to easily switch AMP on/off for debugging\n",
    "scaler = torch.amp.GradScaler(enabled=False)\n",
    "print(f\"AMP GradScaler enabled: {scaler.is_enabled()}\")\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"\\n--- Starting Training Loop ---\")\n",
    "epochs = 5\n",
    "max_grad_norm = 1.0 # Gradient clipping value\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    batch_loss_tracker = 0.0 # Track loss for printing every N batches\n",
    "    correct_tracker = 0 # Track correct predictions for printing every N batches\n",
    "    samples_tracker = 0 # Track number of samples for printing every N batches\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    print_every = 50 # Print stats every 50 batches\n",
    "\n",
    "    for i, batch in enumerate(fast_trainloader):\n",
    "        # Check if batch format is correct\n",
    "        if not (isinstance(batch, (list, tuple)) and len(batch) == 2):\n",
    "             print(f\"Error: DataLoader yielding unexpected batch format: {type(batch)}. Expected (patches, labels).\")\n",
    "             # Handle error appropriately, e.g., skip batch or raise exception\n",
    "             continue # Skip this batch\n",
    "\n",
    "        patches, labels = batch\n",
    "        \n",
    "        # Validate patch shape (optional but helpful)\n",
    "        expected_shape = (patches.shape[0], num_patches, patch_dim[0], patch_dim[1])\n",
    "        if patches.shape != expected_shape:\n",
    "            print(f\"Warning: Batch {i} has unexpected patch shape. Got {patches.shape}, expected {expected_shape}\")\n",
    "            # Decide how to handle this (e.g., skip, reshape if possible)\n",
    "            # continue # Skip if shape is wrong\n",
    "\n",
    "        # Convert labels to indices tensor\n",
    "        try:\n",
    "            label_indices = torch.tensor([class_to_idx[label] for label in labels], dtype=torch.long, device=device)\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Label '{e}' not found in class_to_idx mapping. Skipping batch {i}.\")\n",
    "            continue # Skip batch if a label is invalid\n",
    "\n",
    "        patches = patches.to(device, non_blocking=True)\n",
    "        # label_indices is already created on the correct device\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True) # More memory efficient\n",
    "\n",
    "        # Automatic Mixed Precision context\n",
    "        with amp.autocast(device_type=device.type, enabled=scaler.is_enabled()):\n",
    "            outputs = model(patches) # Forward pass\n",
    "            loss = criterion(outputs, label_indices) # Calculate loss\n",
    "\n",
    "        # Check for NaN/inf loss BEFORE backward pass\n",
    "        if not torch.isfinite(loss):\n",
    "             print(f\"Epoch {epoch+1}, Batch {i+1}: Detected non-finite loss ({loss.detach().item()}). Skipping backward/step.\")\n",
    "             # Consider stopping training or debugging further here\n",
    "             # You might want to inspect `outputs` and `label_indices`\n",
    "             # E.g., print(outputs.min(), outputs.max(), outputs.mean())\n",
    "             continue # Skip optimization steps for this batch\n",
    "\n",
    "        # Backward pass and optimization using scaler\n",
    "        scaler.scale(loss).backward() # Scales loss and calls backward\n",
    "\n",
    "        # Gradient Clipping (unscale gradients before clipping)\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "\n",
    "        scaler.step(optimizer) # Optimizer step (unscales gradients internally)\n",
    "        scaler.update() # Update scaler for next iteration\n",
    "\n",
    "        # --- Statistics Tracking ---\n",
    "        current_loss = loss.detach().item()\n",
    "        running_loss += current_loss\n",
    "        batch_loss_tracker += current_loss\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        batch_correct = (predictions == label_indices).sum().item()\n",
    "        batch_samples = patches.shape[0] # Number of items in the batch\n",
    "\n",
    "        correct_tracker += batch_correct\n",
    "        samples_tracker += batch_samples\n",
    "        total_correct += batch_correct\n",
    "        total_samples += batch_samples\n",
    "\n",
    "        # Print batch statistics periodically\n",
    "        if (i + 1) % print_every == 0 or (i + 1) == len(trainloader):\n",
    "            batch_accuracy = correct_tracker / samples_tracker if samples_tracker > 0 else 0.0\n",
    "            avg_batch_loss = batch_loss_tracker / print_every if (i + 1) % print_every == 0 else batch_loss_tracker / ((i + 1) % print_every)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(trainloader)}], \"\n",
    "                  f\"Avg Batch Loss: {avg_batch_loss:.4f}, Batch Accuracy: {batch_accuracy:.4f}\")\n",
    "            # Reset trackers for the next set of batches\n",
    "            batch_loss_tracker = 0.0\n",
    "            correct_tracker = 0\n",
    "            samples_tracker = 0\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(trainloader) if len(trainloader) > 0 else 0.0\n",
    "    epoch_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "    print(f\"--- Epoch [{epoch+1}/{epochs}] Summary ---\")\n",
    "    print(f\"Average Loss: {epoch_loss:.4f}, Overall Accuracy: {epoch_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"Training Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ada6e33-1ce8-4445-9ed9-0f09bd37e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Setup ---\n"
     ]
    }
   ],
   "source": [
    "# --- Data and Training Setup ---\n",
    "print(\"\\n--- Training Setup ---\")\n",
    "classes = [\n",
    "    'bird', 'dog', 'eight', 'four', 'happy', 'left', 'nine',\n",
    "    'off', 'one', 'seven', 'six', 'three', 'two', 'wow', 'zero',\n",
    "    'bed', 'cat', 'down', 'five', 'go', 'house', 'marvin', 'no',\n",
    "    'on', 'right', 'sheila', 'stop', 'tree', 'up', 'yes'\n",
    "]\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "idx_to_class = {i: cls for cls, i in class_to_idx.items()} # Useful for validation/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "935eab8e-c5d5-43ad-9667-d27b6b95379d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimensions: (64, 105)\n",
      "Patch Dimensions: (16, 15)\n",
      "Number of Patches: 28\n",
      "Patch Flattened Size: 240\n",
      "\n",
      "--- Device Setup ---\n",
      "CUDA Available: True\n",
      "Using CUDA Device: NVIDIA GeForce RTX 4070 Ti\n",
      "CUDA Version: 12.8\n",
      "\n",
      "--- Model Instantiation ---\n",
      "Model created with embed_dim=128\n",
      "\n",
      "--- Training Setup ---\n",
      "LR Scheduler: Warmup (3 epochs) + Cosine Annealing (47 epochs)\n",
      "AMP GradScaler enabled: False\n",
      "\n",
      "--- Starting Training Loop ---\n",
      "Epoch [1/50], Batch [50/200], Avg Batch Loss: 0.0133, Batch Accuracy: 0.0344, LR: 1.0e-05\n",
      "Epoch [1/50], Batch [100/200], Avg Batch Loss: 0.0133, Batch Accuracy: 0.0368, LR: 1.0e-05\n",
      "Epoch [1/50], Batch [150/200], Avg Batch Loss: 0.0133, Batch Accuracy: 0.0436, LR: 1.0e-05\n",
      "Epoch [1/50], Batch [200/200], Avg Batch Loss: 0.0133, Batch Accuracy: 0.0478, LR: 1.0e-05\n",
      "--- Epoch [1/50] Summary ---\n",
      "Average Loss: 3.4000, Overall Accuracy: 0.0406, Final LR: 1.0e-05\n",
      "Validation acc: 0.0655\n",
      "------------------------------\n",
      "Epoch [2/50], Batch [50/200], Avg Batch Loss: 0.0128, Batch Accuracy: 0.0818, LR: 3.4e-04\n",
      "Epoch [2/50], Batch [100/200], Avg Batch Loss: 0.0119, Batch Accuracy: 0.1398, LR: 3.4e-04\n",
      "Epoch [2/50], Batch [150/200], Avg Batch Loss: 0.0113, Batch Accuracy: 0.1809, LR: 3.4e-04\n",
      "Epoch [2/50], Batch [200/200], Avg Batch Loss: 0.0110, Batch Accuracy: 0.2011, LR: 3.4e-04\n",
      "--- Epoch [2/50] Summary ---\n",
      "Average Loss: 3.0040, Overall Accuracy: 0.1508, Final LR: 3.4e-04\n",
      "Validation acc: 0.2301\n",
      "------------------------------\n",
      "Epoch [3/50], Batch [50/200], Avg Batch Loss: 0.0105, Batch Accuracy: 0.2284, LR: 6.7e-04\n",
      "Epoch [3/50], Batch [100/200], Avg Batch Loss: 0.0101, Batch Accuracy: 0.2587, LR: 6.7e-04\n",
      "Epoch [3/50], Batch [150/200], Avg Batch Loss: 0.0097, Batch Accuracy: 0.2797, LR: 6.7e-04\n",
      "Epoch [3/50], Batch [200/200], Avg Batch Loss: 0.0094, Batch Accuracy: 0.3111, LR: 6.7e-04\n",
      "--- Epoch [3/50] Summary ---\n",
      "Average Loss: 2.5375, Overall Accuracy: 0.2694, Final LR: 6.7e-04\n",
      "Validation acc: 0.3352\n",
      "------------------------------\n",
      "Epoch [4/50], Batch [50/200], Avg Batch Loss: 0.0091, Batch Accuracy: 0.3274, LR: 1.0e-03\n",
      "Epoch [4/50], Batch [100/200], Avg Batch Loss: 0.0089, Batch Accuracy: 0.3390, LR: 1.0e-03\n",
      "Epoch [4/50], Batch [150/200], Avg Batch Loss: 0.0086, Batch Accuracy: 0.3543, LR: 1.0e-03\n",
      "Epoch [4/50], Batch [200/200], Avg Batch Loss: 0.0086, Batch Accuracy: 0.3681, LR: 1.0e-03\n",
      "--- Epoch [4/50] Summary ---\n",
      "Average Loss: 2.2493, Overall Accuracy: 0.3472, Final LR: 1.0e-03\n",
      "Validation acc: 0.4114\n",
      "------------------------------\n",
      "Epoch [5/50], Batch [50/200], Avg Batch Loss: 0.0081, Batch Accuracy: 0.3968, LR: 1.0e-03\n",
      "Epoch [5/50], Batch [100/200], Avg Batch Loss: 0.0080, Batch Accuracy: 0.4003, LR: 1.0e-03\n",
      "Epoch [5/50], Batch [150/200], Avg Batch Loss: 0.0078, Batch Accuracy: 0.4195, LR: 1.0e-03\n",
      "Epoch [5/50], Batch [200/200], Avg Batch Loss: 0.0077, Batch Accuracy: 0.4221, LR: 1.0e-03\n",
      "--- Epoch [5/50] Summary ---\n",
      "Average Loss: 2.0168, Overall Accuracy: 0.4097, Final LR: 1.0e-03\n",
      "Validation acc: 0.4544\n",
      "------------------------------\n",
      "Epoch [6/50], Batch [50/200], Avg Batch Loss: 0.0073, Batch Accuracy: 0.4521, LR: 1.0e-03\n",
      "Epoch [6/50], Batch [100/200], Avg Batch Loss: 0.0073, Batch Accuracy: 0.4552, LR: 1.0e-03\n",
      "Epoch [6/50], Batch [150/200], Avg Batch Loss: 0.0073, Batch Accuracy: 0.4584, LR: 1.0e-03\n",
      "Epoch [6/50], Batch [200/200], Avg Batch Loss: 0.0072, Batch Accuracy: 0.4644, LR: 1.0e-03\n",
      "--- Epoch [6/50] Summary ---\n",
      "Average Loss: 1.8519, Overall Accuracy: 0.4575, Final LR: 1.0e-03\n",
      "Validation acc: 0.4779\n",
      "------------------------------\n",
      "Epoch [7/50], Batch [50/200], Avg Batch Loss: 0.0066, Batch Accuracy: 0.4911, LR: 9.9e-04\n",
      "Epoch [7/50], Batch [100/200], Avg Batch Loss: 0.0067, Batch Accuracy: 0.4888, LR: 9.9e-04\n",
      "Epoch [7/50], Batch [150/200], Avg Batch Loss: 0.0068, Batch Accuracy: 0.4850, LR: 9.9e-04\n",
      "Epoch [7/50], Batch [200/200], Avg Batch Loss: 0.0068, Batch Accuracy: 0.4954, LR: 9.9e-04\n",
      "--- Epoch [7/50] Summary ---\n",
      "Average Loss: 1.7193, Overall Accuracy: 0.4901, Final LR: 9.9e-04\n",
      "Validation acc: 0.5012\n",
      "------------------------------\n",
      "Epoch [8/50], Batch [50/200], Avg Batch Loss: 0.0062, Batch Accuracy: 0.5273, LR: 9.8e-04\n",
      "Epoch [8/50], Batch [100/200], Avg Batch Loss: 0.0064, Batch Accuracy: 0.5182, LR: 9.8e-04\n",
      "Epoch [8/50], Batch [150/200], Avg Batch Loss: 0.0064, Batch Accuracy: 0.5188, LR: 9.8e-04\n",
      "Epoch [8/50], Batch [200/200], Avg Batch Loss: 0.0064, Batch Accuracy: 0.5106, LR: 9.8e-04\n",
      "--- Epoch [8/50] Summary ---\n",
      "Average Loss: 1.6226, Overall Accuracy: 0.5188, Final LR: 9.8e-04\n",
      "Validation acc: 0.5203\n",
      "------------------------------\n",
      "Epoch [9/50], Batch [50/200], Avg Batch Loss: 0.0059, Batch Accuracy: 0.5547, LR: 9.7e-04\n",
      "Epoch [9/50], Batch [100/200], Avg Batch Loss: 0.0059, Batch Accuracy: 0.5480, LR: 9.7e-04\n",
      "Epoch [9/50], Batch [150/200], Avg Batch Loss: 0.0060, Batch Accuracy: 0.5444, LR: 9.7e-04\n",
      "Epoch [9/50], Batch [200/200], Avg Batch Loss: 0.0061, Batch Accuracy: 0.5385, LR: 9.7e-04\n",
      "--- Epoch [9/50] Summary ---\n",
      "Average Loss: 1.5235, Overall Accuracy: 0.5464, Final LR: 9.7e-04\n",
      "Validation acc: 0.5312\n",
      "------------------------------\n",
      "Epoch [10/50], Batch [50/200], Avg Batch Loss: 0.0055, Batch Accuracy: 0.5770, LR: 9.6e-04\n",
      "Epoch [10/50], Batch [100/200], Avg Batch Loss: 0.0056, Batch Accuracy: 0.5711, LR: 9.6e-04\n",
      "Epoch [10/50], Batch [150/200], Avg Batch Loss: 0.0057, Batch Accuracy: 0.5613, LR: 9.6e-04\n",
      "Epoch [10/50], Batch [200/200], Avg Batch Loss: 0.0058, Batch Accuracy: 0.5582, LR: 9.6e-04\n",
      "--- Epoch [10/50] Summary ---\n",
      "Average Loss: 1.4454, Overall Accuracy: 0.5669, Final LR: 9.6e-04\n",
      "Validation acc: 0.5357\n",
      "------------------------------\n",
      "Epoch [11/50], Batch [50/200], Avg Batch Loss: 0.0053, Batch Accuracy: 0.5983, LR: 9.5e-04\n",
      "Epoch [11/50], Batch [100/200], Avg Batch Loss: 0.0054, Batch Accuracy: 0.5833, LR: 9.5e-04\n",
      "Epoch [11/50], Batch [150/200], Avg Batch Loss: 0.0054, Batch Accuracy: 0.5877, LR: 9.5e-04\n",
      "Epoch [11/50], Batch [200/200], Avg Batch Loss: 0.0054, Batch Accuracy: 0.5893, LR: 9.5e-04\n",
      "--- Epoch [11/50] Summary ---\n",
      "Average Loss: 1.3684, Overall Accuracy: 0.5896, Final LR: 9.5e-04\n",
      "Validation acc: 0.5637\n",
      "------------------------------\n",
      "Epoch [12/50], Batch [50/200], Avg Batch Loss: 0.0050, Batch Accuracy: 0.6204, LR: 9.3e-04\n",
      "Epoch [12/50], Batch [100/200], Avg Batch Loss: 0.0051, Batch Accuracy: 0.6077, LR: 9.3e-04\n",
      "Epoch [12/50], Batch [150/200], Avg Batch Loss: 0.0052, Batch Accuracy: 0.5944, LR: 9.3e-04\n",
      "Epoch [12/50], Batch [200/200], Avg Batch Loss: 0.0052, Batch Accuracy: 0.5988, LR: 9.3e-04\n",
      "--- Epoch [12/50] Summary ---\n",
      "Average Loss: 1.3063, Overall Accuracy: 0.6053, Final LR: 9.3e-04\n",
      "Validation acc: 0.5587\n",
      "------------------------------\n",
      "Epoch [13/50], Batch [50/200], Avg Batch Loss: 0.0047, Batch Accuracy: 0.6334, LR: 9.1e-04\n",
      "Epoch [13/50], Batch [100/200], Avg Batch Loss: 0.0048, Batch Accuracy: 0.6330, LR: 9.1e-04\n",
      "Epoch [13/50], Batch [150/200], Avg Batch Loss: 0.0049, Batch Accuracy: 0.6173, LR: 9.1e-04\n",
      "Epoch [13/50], Batch [200/200], Avg Batch Loss: 0.0051, Batch Accuracy: 0.6120, LR: 9.1e-04\n",
      "--- Epoch [13/50] Summary ---\n",
      "Average Loss: 1.2405, Overall Accuracy: 0.6240, Final LR: 9.1e-04\n",
      "Validation acc: 0.5585\n",
      "------------------------------\n",
      "Epoch [14/50], Batch [50/200], Avg Batch Loss: 0.0045, Batch Accuracy: 0.6498, LR: 8.9e-04\n",
      "Epoch [14/50], Batch [100/200], Avg Batch Loss: 0.0046, Batch Accuracy: 0.6441, LR: 8.9e-04\n",
      "Epoch [14/50], Batch [150/200], Avg Batch Loss: 0.0047, Batch Accuracy: 0.6335, LR: 8.9e-04\n",
      "Epoch [14/50], Batch [200/200], Avg Batch Loss: 0.0047, Batch Accuracy: 0.6315, LR: 8.9e-04\n",
      "--- Epoch [14/50] Summary ---\n",
      "Average Loss: 1.1864, Overall Accuracy: 0.6397, Final LR: 8.9e-04\n",
      "Validation acc: 0.5765\n",
      "------------------------------\n",
      "Epoch [15/50], Batch [50/200], Avg Batch Loss: 0.0043, Batch Accuracy: 0.6635, LR: 8.7e-04\n",
      "Epoch [15/50], Batch [100/200], Avg Batch Loss: 0.0044, Batch Accuracy: 0.6548, LR: 8.7e-04\n",
      "Epoch [15/50], Batch [150/200], Avg Batch Loss: 0.0045, Batch Accuracy: 0.6510, LR: 8.7e-04\n",
      "Epoch [15/50], Batch [200/200], Avg Batch Loss: 0.0046, Batch Accuracy: 0.6468, LR: 8.7e-04\n",
      "--- Epoch [15/50] Summary ---\n",
      "Average Loss: 1.1350, Overall Accuracy: 0.6541, Final LR: 8.7e-04\n",
      "Validation acc: 0.5708\n",
      "------------------------------\n",
      "Epoch [16/50], Batch [50/200], Avg Batch Loss: 0.0040, Batch Accuracy: 0.6819, LR: 8.5e-04\n",
      "Epoch [16/50], Batch [100/200], Avg Batch Loss: 0.0042, Batch Accuracy: 0.6682, LR: 8.5e-04\n",
      "Epoch [16/50], Batch [150/200], Avg Batch Loss: 0.0044, Batch Accuracy: 0.6587, LR: 8.5e-04\n",
      "Epoch [16/50], Batch [200/200], Avg Batch Loss: 0.0044, Batch Accuracy: 0.6676, LR: 8.5e-04\n",
      "--- Epoch [16/50] Summary ---\n",
      "Average Loss: 1.0857, Overall Accuracy: 0.6691, Final LR: 8.5e-04\n",
      "Validation acc: 0.5859\n",
      "------------------------------\n",
      "Epoch [17/50], Batch [50/200], Avg Batch Loss: 0.0039, Batch Accuracy: 0.6930, LR: 8.2e-04\n",
      "Epoch [17/50], Batch [100/200], Avg Batch Loss: 0.0039, Batch Accuracy: 0.6871, LR: 8.2e-04\n",
      "Epoch [17/50], Batch [150/200], Avg Batch Loss: 0.0042, Batch Accuracy: 0.6686, LR: 8.2e-04\n",
      "Epoch [17/50], Batch [200/200], Avg Batch Loss: 0.0041, Batch Accuracy: 0.6787, LR: 8.2e-04\n",
      "--- Epoch [17/50] Summary ---\n",
      "Average Loss: 1.0284, Overall Accuracy: 0.6819, Final LR: 8.2e-04\n",
      "Validation acc: 0.5843\n",
      "------------------------------\n",
      "Epoch [18/50], Batch [50/200], Avg Batch Loss: 0.0037, Batch Accuracy: 0.7056, LR: 8.0e-04\n",
      "Epoch [18/50], Batch [100/200], Avg Batch Loss: 0.0038, Batch Accuracy: 0.6935, LR: 8.0e-04\n",
      "Epoch [18/50], Batch [150/200], Avg Batch Loss: 0.0040, Batch Accuracy: 0.6879, LR: 8.0e-04\n",
      "Epoch [18/50], Batch [200/200], Avg Batch Loss: 0.0039, Batch Accuracy: 0.6919, LR: 8.0e-04\n",
      "--- Epoch [18/50] Summary ---\n",
      "Average Loss: 0.9821, Overall Accuracy: 0.6947, Final LR: 8.0e-04\n",
      "Validation acc: 0.5859\n",
      "------------------------------\n",
      "Epoch [19/50], Batch [50/200], Avg Batch Loss: 0.0036, Batch Accuracy: 0.7123, LR: 7.7e-04\n",
      "Epoch [19/50], Batch [100/200], Avg Batch Loss: 0.0036, Batch Accuracy: 0.7124, LR: 7.7e-04\n",
      "Epoch [19/50], Batch [150/200], Avg Batch Loss: 0.0037, Batch Accuracy: 0.7044, LR: 7.7e-04\n",
      "Epoch [19/50], Batch [200/200], Avg Batch Loss: 0.0038, Batch Accuracy: 0.6996, LR: 7.7e-04\n",
      "--- Epoch [19/50] Summary ---\n",
      "Average Loss: 0.9478, Overall Accuracy: 0.7072, Final LR: 7.7e-04\n",
      "Validation acc: 0.5969\n",
      "------------------------------\n",
      "Epoch [20/50], Batch [50/200], Avg Batch Loss: 0.0033, Batch Accuracy: 0.7373, LR: 7.4e-04\n",
      "Epoch [20/50], Batch [100/200], Avg Batch Loss: 0.0035, Batch Accuracy: 0.7230, LR: 7.4e-04\n",
      "Epoch [20/50], Batch [150/200], Avg Batch Loss: 0.0036, Batch Accuracy: 0.7123, LR: 7.4e-04\n",
      "Epoch [20/50], Batch [200/200], Avg Batch Loss: 0.0037, Batch Accuracy: 0.7111, LR: 7.4e-04\n",
      "--- Epoch [20/50] Summary ---\n",
      "Average Loss: 0.9004, Overall Accuracy: 0.7209, Final LR: 7.4e-04\n",
      "Validation acc: 0.5946\n",
      "------------------------------\n",
      "Epoch [21/50], Batch [50/200], Avg Batch Loss: 0.0032, Batch Accuracy: 0.7504, LR: 7.1e-04\n",
      "Epoch [21/50], Batch [100/200], Avg Batch Loss: 0.0033, Batch Accuracy: 0.7391, LR: 7.1e-04\n",
      "Epoch [21/50], Batch [150/200], Avg Batch Loss: 0.0034, Batch Accuracy: 0.7320, LR: 7.1e-04\n",
      "Epoch [21/50], Batch [200/200], Avg Batch Loss: 0.0035, Batch Accuracy: 0.7250, LR: 7.1e-04\n",
      "--- Epoch [21/50] Summary ---\n",
      "Average Loss: 0.8497, Overall Accuracy: 0.7366, Final LR: 7.1e-04\n",
      "Validation acc: 0.5943\n",
      "------------------------------\n",
      "Epoch [22/50], Batch [50/200], Avg Batch Loss: 0.0030, Batch Accuracy: 0.7594, LR: 6.8e-04\n",
      "Epoch [22/50], Batch [100/200], Avg Batch Loss: 0.0032, Batch Accuracy: 0.7486, LR: 6.8e-04\n",
      "Epoch [22/50], Batch [150/200], Avg Batch Loss: 0.0032, Batch Accuracy: 0.7416, LR: 6.8e-04\n",
      "Epoch [22/50], Batch [200/200], Avg Batch Loss: 0.0034, Batch Accuracy: 0.7271, LR: 6.8e-04\n",
      "--- Epoch [22/50] Summary ---\n",
      "Average Loss: 0.8164, Overall Accuracy: 0.7442, Final LR: 6.8e-04\n",
      "Validation acc: 0.5996\n",
      "------------------------------\n",
      "Epoch [23/50], Batch [50/200], Avg Batch Loss: 0.0029, Batch Accuracy: 0.7694, LR: 6.5e-04\n",
      "Epoch [23/50], Batch [100/200], Avg Batch Loss: 0.0030, Batch Accuracy: 0.7586, LR: 6.5e-04\n",
      "Epoch [23/50], Batch [150/200], Avg Batch Loss: 0.0031, Batch Accuracy: 0.7484, LR: 6.5e-04\n",
      "Epoch [23/50], Batch [200/200], Avg Batch Loss: 0.0031, Batch Accuracy: 0.7553, LR: 6.5e-04\n",
      "--- Epoch [23/50] Summary ---\n",
      "Average Loss: 0.7721, Overall Accuracy: 0.7579, Final LR: 6.5e-04\n",
      "Validation acc: 0.5986\n",
      "------------------------------\n",
      "Epoch [24/50], Batch [50/200], Avg Batch Loss: 0.0027, Batch Accuracy: 0.7803, LR: 6.2e-04\n",
      "Epoch [24/50], Batch [100/200], Avg Batch Loss: 0.0028, Batch Accuracy: 0.7743, LR: 6.2e-04\n",
      "Epoch [24/50], Batch [150/200], Avg Batch Loss: 0.0029, Batch Accuracy: 0.7672, LR: 6.2e-04\n",
      "Epoch [24/50], Batch [200/200], Avg Batch Loss: 0.0031, Batch Accuracy: 0.7567, LR: 6.2e-04\n",
      "--- Epoch [24/50] Summary ---\n",
      "Average Loss: 0.7362, Overall Accuracy: 0.7697, Final LR: 6.2e-04\n",
      "Validation acc: 0.5936\n",
      "------------------------------\n",
      "Epoch [25/50], Batch [50/200], Avg Batch Loss: 0.0026, Batch Accuracy: 0.7938, LR: 5.9e-04\n",
      "Epoch [25/50], Batch [100/200], Avg Batch Loss: 0.0027, Batch Accuracy: 0.7801, LR: 5.9e-04\n",
      "Epoch [25/50], Batch [150/200], Avg Batch Loss: 0.0028, Batch Accuracy: 0.7746, LR: 5.9e-04\n",
      "Epoch [25/50], Batch [200/200], Avg Batch Loss: 0.0029, Batch Accuracy: 0.7714, LR: 5.9e-04\n",
      "--- Epoch [25/50] Summary ---\n",
      "Average Loss: 0.6956, Overall Accuracy: 0.7800, Final LR: 5.9e-04\n",
      "Validation acc: 0.5965\n",
      "------------------------------\n",
      "Epoch [26/50], Batch [50/200], Avg Batch Loss: 0.0025, Batch Accuracy: 0.8014, LR: 5.5e-04\n",
      "Epoch [26/50], Batch [100/200], Avg Batch Loss: 0.0025, Batch Accuracy: 0.7935, LR: 5.5e-04\n",
      "Epoch [26/50], Batch [150/200], Avg Batch Loss: 0.0027, Batch Accuracy: 0.7777, LR: 5.5e-04\n",
      "Epoch [26/50], Batch [200/200], Avg Batch Loss: 0.0028, Batch Accuracy: 0.7801, LR: 5.5e-04\n",
      "--- Epoch [26/50] Summary ---\n",
      "Average Loss: 0.6667, Overall Accuracy: 0.7882, Final LR: 5.5e-04\n",
      "Validation acc: 0.6022\n",
      "------------------------------\n",
      "Epoch [27/50], Batch [50/200], Avg Batch Loss: 0.0023, Batch Accuracy: 0.8106, LR: 5.2e-04\n",
      "Epoch [27/50], Batch [100/200], Avg Batch Loss: 0.0025, Batch Accuracy: 0.8023, LR: 5.2e-04\n",
      "Epoch [27/50], Batch [150/200], Avg Batch Loss: 0.0025, Batch Accuracy: 0.8054, LR: 5.2e-04\n",
      "Epoch [27/50], Batch [200/200], Avg Batch Loss: 0.0025, Batch Accuracy: 0.7934, LR: 5.2e-04\n",
      "--- Epoch [27/50] Summary ---\n",
      "Average Loss: 0.6241, Overall Accuracy: 0.8029, Final LR: 5.2e-04\n",
      "Validation acc: 0.5987\n",
      "------------------------------\n",
      "Epoch [28/50], Batch [50/200], Avg Batch Loss: 0.0022, Batch Accuracy: 0.8175, LR: 4.9e-04\n",
      "Epoch [28/50], Batch [100/200], Avg Batch Loss: 0.0023, Batch Accuracy: 0.8154, LR: 4.9e-04\n",
      "Epoch [28/50], Batch [150/200], Avg Batch Loss: 0.0024, Batch Accuracy: 0.8091, LR: 4.9e-04\n",
      "Epoch [28/50], Batch [200/200], Avg Batch Loss: 0.0024, Batch Accuracy: 0.8023, LR: 4.9e-04\n",
      "--- Epoch [28/50] Summary ---\n",
      "Average Loss: 0.5942, Overall Accuracy: 0.8111, Final LR: 4.9e-04\n",
      "Validation acc: 0.6061\n",
      "------------------------------\n",
      "Epoch [29/50], Batch [50/200], Avg Batch Loss: 0.0021, Batch Accuracy: 0.8256, LR: 4.6e-04\n",
      "Epoch [29/50], Batch [100/200], Avg Batch Loss: 0.0022, Batch Accuracy: 0.8210, LR: 4.6e-04\n",
      "Epoch [29/50], Batch [150/200], Avg Batch Loss: 0.0022, Batch Accuracy: 0.8145, LR: 4.6e-04\n",
      "Epoch [29/50], Batch [200/200], Avg Batch Loss: 0.0023, Batch Accuracy: 0.8152, LR: 4.6e-04\n",
      "--- Epoch [29/50] Summary ---\n",
      "Average Loss: 0.5662, Overall Accuracy: 0.8191, Final LR: 4.6e-04\n",
      "Validation acc: 0.6072\n",
      "------------------------------\n",
      "Epoch [30/50], Batch [50/200], Avg Batch Loss: 0.0020, Batch Accuracy: 0.8386, LR: 4.2e-04\n",
      "Epoch [30/50], Batch [100/200], Avg Batch Loss: 0.0021, Batch Accuracy: 0.8345, LR: 4.2e-04\n",
      "Epoch [30/50], Batch [150/200], Avg Batch Loss: 0.0021, Batch Accuracy: 0.8291, LR: 4.2e-04\n",
      "Epoch [30/50], Batch [200/200], Avg Batch Loss: 0.0021, Batch Accuracy: 0.8298, LR: 4.2e-04\n",
      "--- Epoch [30/50] Summary ---\n",
      "Average Loss: 0.5281, Overall Accuracy: 0.8330, Final LR: 4.2e-04\n",
      "Validation acc: 0.6090\n",
      "------------------------------\n",
      "Epoch [31/50], Batch [50/200], Avg Batch Loss: 0.0019, Batch Accuracy: 0.8509, LR: 3.9e-04\n",
      "Epoch [31/50], Batch [100/200], Avg Batch Loss: 0.0019, Batch Accuracy: 0.8411, LR: 3.9e-04\n",
      "Epoch [31/50], Batch [150/200], Avg Batch Loss: 0.0020, Batch Accuracy: 0.8413, LR: 3.9e-04\n",
      "Epoch [31/50], Batch [200/200], Avg Batch Loss: 0.0021, Batch Accuracy: 0.8302, LR: 3.9e-04\n",
      "--- Epoch [31/50] Summary ---\n",
      "Average Loss: 0.5035, Overall Accuracy: 0.8409, Final LR: 3.9e-04\n",
      "Validation acc: 0.6036\n",
      "------------------------------\n",
      "Epoch [32/50], Batch [50/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8616, LR: 3.6e-04\n",
      "Epoch [32/50], Batch [100/200], Avg Batch Loss: 0.0019, Batch Accuracy: 0.8470, LR: 3.6e-04\n",
      "Epoch [32/50], Batch [150/200], Avg Batch Loss: 0.0019, Batch Accuracy: 0.8399, LR: 3.6e-04\n",
      "Epoch [32/50], Batch [200/200], Avg Batch Loss: 0.0019, Batch Accuracy: 0.8425, LR: 3.6e-04\n",
      "--- Epoch [32/50] Summary ---\n",
      "Average Loss: 0.4774, Overall Accuracy: 0.8478, Final LR: 3.6e-04\n",
      "Validation acc: 0.6109\n",
      "------------------------------\n",
      "Epoch [33/50], Batch [50/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8602, LR: 3.3e-04\n",
      "Epoch [33/50], Batch [100/200], Avg Batch Loss: 0.0018, Batch Accuracy: 0.8546, LR: 3.3e-04\n",
      "Epoch [33/50], Batch [150/200], Avg Batch Loss: 0.0018, Batch Accuracy: 0.8507, LR: 3.3e-04\n",
      "Epoch [33/50], Batch [200/200], Avg Batch Loss: 0.0018, Batch Accuracy: 0.8484, LR: 3.3e-04\n",
      "--- Epoch [33/50] Summary ---\n",
      "Average Loss: 0.4559, Overall Accuracy: 0.8535, Final LR: 3.3e-04\n",
      "Validation acc: 0.6047\n",
      "------------------------------\n",
      "Epoch [34/50], Batch [50/200], Avg Batch Loss: 0.0016, Batch Accuracy: 0.8691, LR: 3.0e-04\n",
      "Epoch [34/50], Batch [100/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8636, LR: 3.0e-04\n",
      "Epoch [34/50], Batch [150/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8570, LR: 3.0e-04\n",
      "Epoch [34/50], Batch [200/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8619, LR: 3.0e-04\n",
      "--- Epoch [34/50] Summary ---\n",
      "Average Loss: 0.4288, Overall Accuracy: 0.8629, Final LR: 3.0e-04\n",
      "Validation acc: 0.6112\n",
      "------------------------------\n",
      "Epoch [35/50], Batch [50/200], Avg Batch Loss: 0.0015, Batch Accuracy: 0.8758, LR: 2.7e-04\n",
      "Epoch [35/50], Batch [100/200], Avg Batch Loss: 0.0016, Batch Accuracy: 0.8713, LR: 2.7e-04\n",
      "Epoch [35/50], Batch [150/200], Avg Batch Loss: 0.0016, Batch Accuracy: 0.8695, LR: 2.7e-04\n",
      "Epoch [35/50], Batch [200/200], Avg Batch Loss: 0.0017, Batch Accuracy: 0.8633, LR: 2.7e-04\n",
      "--- Epoch [35/50] Summary ---\n",
      "Average Loss: 0.4072, Overall Accuracy: 0.8700, Final LR: 2.7e-04\n",
      "Validation acc: 0.6065\n",
      "------------------------------\n",
      "Epoch [36/50], Batch [50/200], Avg Batch Loss: 0.0015, Batch Accuracy: 0.8813, LR: 2.4e-04\n",
      "Epoch [36/50], Batch [100/200], Avg Batch Loss: 0.0015, Batch Accuracy: 0.8811, LR: 2.4e-04\n",
      "Epoch [36/50], Batch [150/200], Avg Batch Loss: 0.0015, Batch Accuracy: 0.8814, LR: 2.4e-04\n",
      "Epoch [36/50], Batch [200/200], Avg Batch Loss: 0.0016, Batch Accuracy: 0.8706, LR: 2.4e-04\n",
      "--- Epoch [36/50] Summary ---\n",
      "Average Loss: 0.3820, Overall Accuracy: 0.8786, Final LR: 2.4e-04\n",
      "Validation acc: 0.6094\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 220\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# It's good practice to wrap the dataloader with enumerate\u001b[39;00m\n\u001b[32m    218\u001b[39m num_batches = \u001b[38;5;28mlen\u001b[39m(fast_trainloader)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfast_trainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError: DataLoader yielding unexpected batch format: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. Expected (patches, labels).\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Envs/DeepLearning/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import amp # For automatic mixed precision\n",
    "# --- NEW IMPORTS ---\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "# --- /NEW IMPORTS ---\n",
    "\n",
    "# --- Transformer Block Definition (Unchanged) ---\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.mha(x_norm, x_norm, x_norm)\n",
    "        x = x + self.dropout1(attn_out)\n",
    "        x_norm = self.norm2(x)\n",
    "        ffn_out = self.ffn(x_norm)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "        return x\n",
    "\n",
    "# --- Simplified Transformer Model Definition (Unchanged) ---\n",
    "class TransformerSimplified(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_patches: int,\n",
    "                 patch_flat: int,\n",
    "                 embed_dim: int = 64,\n",
    "                 num_heads: int = 8,\n",
    "                 ff_dim: int = 1024,\n",
    "                 num_layers: int = 20,\n",
    "                 num_classes: int = 30,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embed_dim ({embed_dim}) must be divisible by num_heads ({num_heads})\")\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_patches = num_patches\n",
    "        self.embed = nn.Linear(patch_flat, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.zeros_(m.bias)\n",
    "            nn.init.ones_(m.weight)\n",
    "        # Removed Parameter check as it's handled by direct init above\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        P = self.num_patches\n",
    "        x = x.view(B, P, -1)\n",
    "        x = self.embed(x)\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        cls_output = x[:, 0]\n",
    "        logits = self.head(cls_output)\n",
    "        return logits\n",
    "\n",
    "# --- Configuration ---\n",
    "# Assuming img_dim and patch_dim are defined elsewhere\n",
    "# img_dim = (64, 105)\n",
    "# patch_dim = (16, 15)\n",
    "\n",
    "# Calculate number of patches and flattened patch size\n",
    "if (img_dim[0] % patch_dim[0] != 0) or (img_dim[1] % patch_dim[1] != 0):\n",
    "    raise ValueError(\"Image dimensions must be divisible by patch dimensions\")\n",
    "num_patches_h = img_dim[0] // patch_dim[0]\n",
    "num_patches_w = img_dim[1] // patch_dim[1]\n",
    "num_patches = num_patches_h * num_patches_w\n",
    "patch_flat = patch_dim[0] * patch_dim[1] * 1 # Assuming 1 channel\n",
    "\n",
    "print(f\"Image Dimensions: {img_dim}\")\n",
    "print(f\"Patch Dimensions: {patch_dim}\")\n",
    "print(f\"Number of Patches: {num_patches}\")\n",
    "print(f\"Patch Flattened Size: {patch_flat}\")\n",
    "\n",
    "# --- Device Setup (Unchanged) ---\n",
    "print(\"\\n--- Device Setup ---\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"CUDA Available: True\")\n",
    "    print(f\"Using CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"CUDA Available: False\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Model Instantiation (Unchanged)---\n",
    "print(\"\\n--- Model Instantiation ---\")\n",
    "model = TransformerSimplified(\n",
    "    num_patches=num_patches,\n",
    "    patch_flat=patch_flat,\n",
    "    embed_dim=128,\n",
    "    num_heads=8,\n",
    "    ff_dim=512,\n",
    "    num_layers=8,\n",
    "    num_classes=30, # num_classes already defined\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "print(f\"Model created with embed_dim={model.embed_dim}\")\n",
    "\n",
    "\n",
    "# --- Data Setup (Assuming defined elsewhere) ---\n",
    "# Make sure trainloader (or fast_trainloader) and classes are defined\n",
    "# Example:\n",
    "# trainloader = ...\n",
    "# classes = [...]\n",
    "# class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "# idx_to_class = {i: cls for cls, i in class_to_idx.items()}\n",
    "# num_classes = len(classes) # Ensure this matches model's num_classes\n",
    "\n",
    "\n",
    "# --- Training Setup ---\n",
    "print(\"\\n--- Training Setup ---\")\n",
    "\n",
    "# --- NEW: Training Hyperparameters ---\n",
    "epochs = 50          # INCREASED: Train for significantly longer\n",
    "base_lr = 1e-3       # ADJUSTED: Starting point, can be tuned (e.g., 1e-4, 5e-4)\n",
    "warmup_epochs = 3    # Number of epochs for linear warmup\n",
    "min_lr = 1e-5        # Minimum learning rate for cosine annealing\n",
    "weight_decay = 0.075  # Weight decay for AdamW (typical value for ViTs)\n",
    "max_grad_norm = 1.0  # Gradient clipping value (Unchanged)\n",
    "batch_size = 256     # Keep consistent with DataLoader (Unchanged)\n",
    "# --- /NEW: Training Hyperparameters ---\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- NEW: Learning Rate Scheduler Setup ---\n",
    "# 1. Linear Warmup Scheduler\n",
    "# Starts from a factor relative to base_lr, ends at base_lr\n",
    "warmup_start_factor = min_lr / base_lr # Start near minimum LR\n",
    "warmup_scheduler = LinearLR(optimizer,\n",
    "                           start_factor=warmup_start_factor,\n",
    "                           end_factor=1.0,\n",
    "                           total_iters=warmup_epochs)\n",
    "\n",
    "# 2. Cosine Annealing Scheduler (main phase)\n",
    "# Starts after warmup, decays to min_lr\n",
    "cosine_epochs = epochs - warmup_epochs\n",
    "main_scheduler = CosineAnnealingLR(optimizer,\n",
    "                                 T_max=cosine_epochs,\n",
    "                                 eta_min=min_lr)\n",
    "\n",
    "# 3. Combine Schedulers\n",
    "# Use warmup_scheduler for warmup_epochs, then switch to main_scheduler\n",
    "scheduler = SequentialLR(optimizer,\n",
    "                       schedulers=[warmup_scheduler, main_scheduler],\n",
    "                       milestones=[warmup_epochs])\n",
    "print(f\"LR Scheduler: Warmup ({warmup_epochs} epochs) + Cosine Annealing ({cosine_epochs} epochs)\")\n",
    "# --- /NEW: Learning Rate Scheduler Setup ---\n",
    "\n",
    "\n",
    "# Automatic Mixed Precision Scaler\n",
    "# --- MODIFIED: Enable AMP ---\n",
    "scaler = torch.amp.GradScaler(enabled=False)\n",
    "print(f\"AMP GradScaler enabled: {scaler.is_enabled()}\")\n",
    "# --- /MODIFIED: Enable AMP ---\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"\\n--- Starting Training Loop ---\")\n",
    "print_every = 50 # Print stats every 50 batches\n",
    "\n",
    "# Assume `fast_trainloader` is your DataLoader instance\n",
    "# Ensure it's defined correctly before this loop\n",
    "if 'fast_trainloader' not in locals():\n",
    "     raise NameError(\"DataLoader 'fast_trainloader' is not defined.\")\n",
    "if 'class_to_idx' not in locals():\n",
    "     raise NameError(\"'class_to_idx' mapping is not defined.\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_loss_tracker = 0.0\n",
    "    correct_tracker = 0\n",
    "    samples_tracker = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # It's good practice to wrap the dataloader with enumerate\n",
    "    num_batches = len(fast_trainloader)\n",
    "\n",
    "    for i, batch in enumerate(fast_trainloader):\n",
    "        if not (isinstance(batch, (list, tuple)) and len(batch) == 2):\n",
    "            print(f\"Error: DataLoader yielding unexpected batch format: {type(batch)}. Expected (patches, labels).\")\n",
    "            continue\n",
    "\n",
    "        patches, labels = batch\n",
    "\n",
    "        # Ensure patches are float (common requirement, esp. for AMP)\n",
    "        # and labels are appropriate type (e.g., strings if they are keys for class_to_idx)\n",
    "        if not isinstance(patches, torch.Tensor) or patches.dtype != torch.float32:\n",
    "             # Add conversion if necessary, e.g., patches = patches.float()\n",
    "             # Or ensure your DataLoader yields float tensors\n",
    "             pass # Assuming patches are already correct float tensors\n",
    "\n",
    "        # Validate patch shape (optional but helpful)\n",
    "        # Assuming patches input to model should be (B, P, Patch_H, Patch_W) initially\n",
    "        # B = patches.shape[0] # Batch size from current batch\n",
    "        # expected_shape = (B, num_patches, patch_dim[0], patch_dim[1]) # Requires patch_dim to be defined\n",
    "        # if patches.shape[1:] != expected_shape[1:]: # Check dimensions after batch\n",
    "        #      print(f\"Warning: Batch {i} has unexpected patch shape. Got {patches.shape}, expected {expected_shape}\")\n",
    "             # continue # Skip if shape is wrong - uncomment if strict checking needed\n",
    "\n",
    "        try:\n",
    "            label_indices = torch.tensor([class_to_idx[label] for label in labels], dtype=torch.long, device=device)\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Label '{e}' not found in class_to_idx mapping. Skipping batch {i}.\")\n",
    "            continue\n",
    "        except TypeError:\n",
    "             # Handle cases where labels might already be indices (tensors)\n",
    "             if isinstance(labels, torch.Tensor):\n",
    "                 label_indices = labels.to(device=device, dtype=torch.long)\n",
    "             else:\n",
    "                 print(f\"Error: Unexpected label type: {type(labels)}. Skipping batch {i}.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "        patches = patches.to(device, non_blocking=True)\n",
    "        # label_indices is already created on/moved to the correct device\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with amp.autocast(device_type=device.type, enabled=scaler.is_enabled()):\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, label_indices)\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}/{num_batches}: Detected non-finite loss ({loss.detach().item()}). Skipping backward/step.\")\n",
    "            # Consider adding code here to log problematic inputs/outputs for debugging\n",
    "            continue\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer) # Unscale gradients before clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # --- Statistics Tracking (Unchanged) ---\n",
    "        current_loss = loss.detach().item()\n",
    "        running_loss += current_loss\n",
    "        batch_loss_tracker += current_loss\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        batch_correct = (predictions == label_indices).sum().item()\n",
    "        batch_samples = patches.shape[0]\n",
    "        correct_tracker += batch_correct\n",
    "        samples_tracker += batch_samples\n",
    "        total_correct += batch_correct\n",
    "        total_samples += batch_samples\n",
    "\n",
    "        if (i + 1) % print_every == 0 or (i + 1) == num_batches:\n",
    "             # Calculate average over the tracked period\n",
    "             avg_batch_loss = batch_loss_tracker / samples_tracker if samples_tracker > 0 else 0.0\n",
    "             batch_accuracy = correct_tracker / samples_tracker if samples_tracker > 0 else 0.0\n",
    "             # Get current Learning Rate from the optimizer\n",
    "             current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "             print(f\"Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{num_batches}], \"\n",
    "                   f\"Avg Batch Loss: {avg_batch_loss:.4f}, Batch Accuracy: {batch_accuracy:.4f}, \"\n",
    "                   f\"LR: {current_lr:.1e}\") # Display current LR\n",
    "\n",
    "             # Reset trackers for the next print interval\n",
    "             batch_loss_tracker = 0.0\n",
    "             correct_tracker = 0\n",
    "             samples_tracker = 0\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    epoch_loss = running_loss / num_batches if num_batches > 0 else 0.0\n",
    "    epoch_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "    # Get LR at the end of the epoch (after scheduler step)\n",
    "    final_epoch_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"--- Epoch [{epoch+1}/{epochs}] Summary ---\")\n",
    "    print(f\"Average Loss: {epoch_loss:.4f}, Overall Accuracy: {epoch_accuracy:.4f}, Final LR: {final_epoch_lr:.1e}\")\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    no_labels_val = 0\n",
    "    for patches_val, labels_val in valloader:\n",
    "        patches_val= patches_val.to(device)\n",
    "        label_indices = torch.tensor([class_to_idx[label] for label in labels_val], device=device)\n",
    "        \n",
    "        outputs = model(patches_val)\n",
    "        \n",
    "        correct_val += (outputs.argmax(dim=1) == label_indices).sum().item()\n",
    "        no_labels_val += patches_val.shape[0]\n",
    "    print(f\"Validation acc: {correct_val/no_labels_val:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- IMPORTANT: Step the Scheduler after each epoch ---\n",
    "    scheduler.step()\n",
    "    # --- /IMPORTANT ---\n",
    "\n",
    "\n",
    "print(\"Training Finished.\")\n",
    "\n",
    "# Remember to also implement validation loops to monitor generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0798e4-2d53-4097-aced-e300c199c597",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ac1371-d31a-43d7-bc0c-1e35960b97bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"transformer_1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ef1b7d-092a-4b8c-befa-6487b9f17fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42832ee6-28ac-41f8-8535-cbebc7bd369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i, (batch, labels) in enumerate(valloader):\n",
    "    batch = batch.to(device)\n",
    "    outputs = model(batch)\n",
    "    label_indices = torch.tensor([class_to_idx[label] for label in labels], dtype=torch.long, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80d84897-75d6-43d6-876d-98951a46e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lll2 = torch.tensor([class_to_idx[label] for label in lll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b409f498-acef-4b9b-a596-7811965da5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53cd4d17-aeca-4a6a-9df0-4a849469e00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkk.argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8a482fd-af57-4fb6-9170-6cebb197da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "624612c8-bc0b-4f19-9da4-820e7314e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([PosixPath('/home/mpuscian/Desktop/repozytoria/MINI_projects/Transformers/data/processed/splited_data/validation')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array([pathlib.Path(path).parents[1] for path in valset.paths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d133bcd0-724f-4b14-b3c9-161913fd6a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([PosixPath('/home/mpuscian/Desktop/repozytoria/MINI_projects/Transformers/data/processed/splited_data/train')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array([pathlib.Path(path).parents[1] for path in trainset.paths]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLKernel",
   "language": "python",
   "name": "dlkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
